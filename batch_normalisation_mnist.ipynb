{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vivek-84/ANN_Callback-Keras/blob/main/batch_normalisation_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HwplHsTXWFw"
      },
      "source": [
        "1. Theory and Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOEjIB5lXvyM"
      },
      "source": [
        "Explain the concept of batch normalization in the context of Artificial Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9bXbR29Ym2S"
      },
      "source": [
        "Batch Normalization (BN) is a technique used in Artificial Neural Networks (ANNs) to improve the training speed and stability of deep neural networks. It was introduced by Sergey Ioffe and Christian Szegedy in their 2015 paper titled \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.\"\n",
        "\n",
        "The main idea behind Batch Normalization is to normalize the inputs of each layer in a neural network during training. The normalization is performed across mini-batches of data, hence the name \"batch\" normalization. The normalization process involves the following steps:\n",
        "\n",
        "1. **Compute Batch Mean and Variance:**\n",
        "   For each mini-batch of data, compute the mean and variance of the activations across all the examples in the batch.\n",
        "\n",
        "2. **Normalize the Activations:**\n",
        "   Normalize the activations of the current layer by subtracting the mean and dividing by the standard deviation (after adding a small constant for numerical stability).\n",
        "\n",
        "3. **Scale and Shift:**\n",
        "   Introduce two additional learnable parameters, γ (gamma) and β (beta), for each normalized activation. These parameters allow the network to learn the optimal scale and shift for the normalized activations.\n",
        "\n",
        "4. **Update during Training:**\n",
        "   During training, the mean and variance are computed using the current mini-batch, and the moving averages are updated. This helps the model adapt to the changing distribution of the data over time.\n",
        "\n",
        "The batch normalization process has several advantages:\n",
        "\n",
        "- **Stabilizes Training:**\n",
        "  Batch Normalization helps in reducing the internal covariate shift, which refers to the change in the distribution of the network activations during training. This stabilization often results in faster and more stable convergence.\n",
        "\n",
        "- **Allows Higher Learning Rates:**\n",
        "  The normalization of inputs makes it possible to use higher learning rates during training, which can speed up the convergence of the model.\n",
        "\n",
        "- **Reduces Sensitivity to Initialization:**\n",
        "  Batch Normalization reduces the sensitivity of a network to the choice of weight initialization. This can be particularly beneficial when dealing with deep networks.\n",
        "\n",
        "- **Acts as Regularization:**\n",
        "  The normalization process has a slight regularization effect, which can reduce the need for other regularization techniques like dropout.\n",
        "\n",
        "Batch Normalization is commonly applied to the input of each layer or to the output of fully connected or convolutional layers. It has become a standard component in the training of deep neural networks and is widely used in various architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfeXP8QNYxPA"
      },
      "source": [
        "Describe the benefits of using batch normalization during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2vckOduaNrp"
      },
      "source": [
        "Batch Normalization (BN) offers several benefits during the training of neural networks, contributing to faster convergence, improved stability, and better generalization. Here are the key advantages of using batch normalization:\n",
        "\n",
        "1. **Accelerated Training Convergence:**\n",
        "   Batch Normalization reduces internal covariate shift by normalizing the activations, making the optimization landscape more well-behaved. This often leads to faster convergence during training. Networks with BN layers tend to require fewer training iterations to reach a certain level of performance.\n",
        "\n",
        "2. **Stabilization of Training:**\n",
        "   Internal covariate shift, the change in the distribution of the network activations during training, can slow down the training process. Batch Normalization mitigates this shift by normalizing the inputs, making the training more stable and robust. This stability allows the use of higher learning rates, further accelerating training.\n",
        "\n",
        "3. **Reduced Sensitivity to Weight Initialization:**\n",
        "   Batch Normalization reduces the sensitivity of a neural network to the choice of weight initialization. This is particularly beneficial in deep networks where getting the initialization right can be challenging. The normalization process allows for more flexibility in choosing initial weights, making it easier to train deep architectures.\n",
        "\n",
        "4. **Mitigation of Vanishing and Exploding Gradients:**\n",
        "   Batch Normalization helps in addressing the vanishing and exploding gradient problems, which are common issues in deep networks. By normalizing the inputs, BN helps maintain a stable scale of activations throughout the network, preventing gradients from becoming too small or too large.\n",
        "\n",
        "5. **Enabling Higher Learning Rates:**\n",
        "   With the stabilized training and reduced sensitivity to initialization, Batch Normalization allows the use of higher learning rates. This is advantageous as higher learning rates can speed up the convergence of the model, enabling it to reach a good solution more quickly.\n",
        "\n",
        "6. **Regularization Effect:**\n",
        "   Batch Normalization has a slight regularization effect due to the introduction of the learnable scale and shift parameters (γ and β). This can reduce the need for other regularization techniques, such as dropout, and help prevent overfitting.\n",
        "\n",
        "7. **Improved Generalization:**\n",
        "   The normalization of activations helps improve the generalization performance of the model. By normalizing the inputs across mini-batches, BN encourages the model to learn features that are more invariant to variations in the input distribution, leading to better generalization to unseen data.\n",
        "\n",
        "8. **Compatibility with Various Architectures:**\n",
        "   Batch Normalization is a versatile technique that can be applied to different types of layers, including fully connected layers, convolutional layers, and recurrent layers. Its compatibility with various architectures makes it a widely adopted normalization technique in modern neural networks.\n",
        "\n",
        "In summary, Batch Normalization plays a crucial role in improving the efficiency and effectiveness of training deep neural networks by addressing common challenges associated with internal covariate shift, vanishing/exploding gradients, and sensitivity to weight initialization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3SilSz_apCy"
      },
      "source": [
        "Discuss the working principle of batch normalization, including the normalization step and the learnable\n",
        "parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irBqBvAGbDvM"
      },
      "source": [
        "The working principle of Batch Normalization (BN) involves normalizing the inputs of each layer in a neural network during training. The normalization is performed across mini-batches of data, and the process includes both normalization and the introduction of learnable parameters. Let's break down the key steps:\n",
        "\n",
        "### 1. Normalization Step:\n",
        "\n",
        "For each mini-batch of data during training, the normalization step involves the following:\n",
        "\n",
        "#### a. Compute Batch Mean and Variance:\n",
        "   - Compute the mean (\\(\\mu_B\\)) and variance (\\(\\sigma_B^2\\)) of the activations across all the examples in the mini-batch.\n",
        "\n",
        "#### b. Normalize Activations:\n",
        "   - Normalize the activations (\\(x_i\\)) of the current layer using the batch mean and variance:\n",
        "     \\[ \\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}} \\]\n",
        "   Here, \\(\\epsilon\\) is a small constant added for numerical stability.\n",
        "\n",
        "#### c. Scale and Shift:\n",
        "   - Introduce two learnable parameters for each normalized activation: \\( \\gamma \\) (gamma) and \\( \\beta \\) (beta).\n",
        "   - Scale and shift the normalized activations:\n",
        "     \\[ y_i = \\gamma \\hat{x}_i + \\beta \\]\n",
        "   The parameters \\( \\gamma \\) and \\( \\beta \\) allow the network to learn the optimal scale and shift for the normalized activations.\n",
        "\n",
        "### 2. Learnable Parameters:\n",
        "\n",
        "#### a. Scale Parameter (\\( \\gamma \\)):\n",
        "   - \\( \\gamma \\) is a learnable parameter that scales the normalized activations.\n",
        "   - It allows the network to learn whether to amplify or diminish the normalized values based on the needs of the task.\n",
        "\n",
        "#### b. Shift Parameter (\\( \\beta \\)):\n",
        "   - \\( \\beta \\) is a learnable parameter that shifts the normalized activations.\n",
        "   - It allows the network to learn an optimal bias or offset for the normalized values.\n",
        "\n",
        "### 3. Update during Training:\n",
        "\n",
        "During training, the mean ((mu)) and variance ((sigma^2\\)) are computed using the current mini-batch. Additionally, moving averages of the mean and variance are maintained across mini-batches. The moving averages are used during inference to normalize inputs consistently.\n",
        "\n",
        "The normalization and learnable parameters are applied independently to each input channel, feature map, or neuron, depending on the layer's type.\n",
        "\n",
        "### 4. Batch Normalization during Inference:\n",
        "\n",
        "During inference (or testing), the learned moving averages of mean and variance are used for normalization. The scale (\\( \\gamma \\)) and shift (\\( \\beta \\)) parameters, learned during training, are applied to the normalized inputs.\n",
        "\n",
        "### Benefits:\n",
        "\n",
        "- **Stabilization:** Batch Normalization helps stabilize training by reducing internal covariate shift, resulting in faster convergence.\n",
        "  \n",
        "- **Regularization:** The learnable parameters ( gamma ) and ( beta ) introduce a slight regularization effect, reducing the need for additional regularization techniques.\n",
        "\n",
        "- **Flexibility:** Batch Normalization is applicable to various layer types, including fully connected, convolutional, and recurrent layers.\n",
        "\n",
        "Batch Normalization has become a standard component in the training of deep neural networks due to its effectiveness in addressing training challenges and improving the convergence and generalization of models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZzOqt0hdGPi"
      },
      "source": [
        "2. Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGa0P6A7g0hs"
      },
      "source": [
        "Choose a dataset of your choice(MNIST) and preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XM4QcpTg1XY"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,BatchNormalization,Dropout\n",
        "from keras.layers import LeakyReLU,Conv2D,MaxPooling2D,AveragePooling2D\n",
        "from keras import regularizers\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Mnist dataset from tensorflow\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train_full, y_train_full) , (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "pHEJDi_MIJUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of Mnist dataset\n",
        "print(x_train_full.shape) # Training data shape\n",
        "print(x_test.shape) # Testing data shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYUFJyDvIOSf",
        "outputId": "568d147c-458b-4945-98bf-da1832b799aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 60000 image of handwritten digits and each image has resolution 28*28 which is equal to 784 pixels"
      ],
      "metadata": {
        "id": "7ZjU0_aPISYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is some example\n",
        "k = 5\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(1,k+1):\n",
        " plt.subplot(1,k,i)\n",
        " idx = int(np.random.randint(0,60000,1))\n",
        " plt.imshow(x_train_full[idx], cmap=\"binary\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "w5-wd85kIddD",
        "outputId": "7c773b74-5cc7-4cae-fe6d-11afd63b4e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_full[0] # Image at \"0\" index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnXO1OEKIlxw",
        "outputId": "5deb495e-fc0b-4915-b6ff-92dedc3dde85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_full[0] # Number at \"0\" index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_5BrPliImyo",
        "outputId": "ec66dd80-e34a-4b07-e33a-0f959e39b3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the pixels value between 0 to 1\n",
        "x_valid, x_train = x_train_full[:5000]/255, x_train_full[5000:]/255\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "x_test = x_test/255\n"
      ],
      "metadata": {
        "id": "7WqieLtqIvKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a simple feedforward neural network using any deep learning framework/library (e.g.,\n",
        "Tensorflow, PyTorch)"
      ],
      "metadata": {
        "id": "FrYhXS4DJCwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the layers\n",
        "LAYERS = [\n",
        " tf.keras.layers.Flatten(input_shape=[28,28],name=\"inputLayer\"),\n",
        " tf.keras.layers.Dense(300,activation=\"relu\",name=\"hiddenLayer1\"),\n",
        " tf.keras.layers.Dense(100,activation=\"relu\",name=\"hiddenLayer2\"),\n",
        " tf.keras.layers.Dense(10,activation=\"softmax\",name=\"outputLayer\")\n",
        "]\n",
        "model = tf.keras.models.Sequential(LAYERS)\n"
      ],
      "metadata": {
        "id": "TVQJkm45JK4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # Summary of the model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtiPwGnPJxF_",
        "outputId": "8520fb58-e15b-4eec-a53b-3d3bf1404a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputLayer (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " hiddenLayer1 (Dense)        (None, 300)               235500    \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 100)               30100     \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266610 (1.02 MB)\n",
            "Trainable params: 266610 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = model.layers[0]\n",
        "input_layer.get_weights()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m22CizLCKA1-",
        "outputId": "f52a80fd-bc07-4344-9e86-2df5bd685682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer has no weights"
      ],
      "metadata": {
        "id": "ivK6CFjGKEMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = model.layers[1]\n",
        "hidden1.get_weights() # The weights of first hidden layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_5Yd9EjKv_3",
        "outputId": "edd2ef87-8a1d-4bc1-a01c-3949c00ae670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-2.1447539e-03, -7.0880234e-02, -7.2773233e-02, ...,\n",
              "          7.2414190e-02, -6.6001475e-02, -4.3234579e-02],\n",
              "        [-4.8865110e-02, -7.1376562e-05,  3.5336271e-02, ...,\n",
              "         -3.0936483e-02, -1.5900601e-02,  6.3845962e-03],\n",
              "        [-3.2321736e-03,  9.1256797e-03,  7.0472792e-02, ...,\n",
              "         -4.5356773e-02,  1.3580471e-03,  6.8725958e-02],\n",
              "        ...,\n",
              "        [-3.9385006e-02, -6.9646657e-02,  1.5591808e-02, ...,\n",
              "          2.2587009e-02,  5.0430968e-02, -4.0258311e-02],\n",
              "        [-4.6156004e-02,  6.5931439e-02,  2.6721530e-02, ...,\n",
              "          7.1301013e-02,  1.4828332e-02, -2.1825880e-02],\n",
              "        [-3.1501416e-02, -6.9585085e-02,  6.8454295e-02, ...,\n",
              "          3.3825889e-02,  1.0015003e-02, -4.5447044e-02]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Loss_function,Optimizer,Metrics and compiling the model\n",
        "loss_function = \"sparse_categorical_crossentropy\"\n",
        "\n",
        "OPTIMIZER = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "METRICS = [\"accuracy\"]\n",
        "model.compile(\n",
        " loss=loss_function,\n",
        " optimizer=OPTIMIZER,\n",
        " metrics=METRICS\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "38m5ta9zK4sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for saving the logs at proper folder\n",
        "def get_log_path(log_dir=\"logs/fit\"):\n",
        " filename = time.strftime(\"1_log_%y_%m_%d_%H_%M_%S\")\n",
        " logs_path = os.path.join(log_dir,filename)\n",
        " print(f\"Saving logs at {logs_path}\")\n",
        " return logs_path\n"
      ],
      "metadata": {
        "id": "B5kCGkeiLJPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating logs callback\n",
        "log_dirs = get_log_path()\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dirs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfmvrW_yLRRL",
        "outputId": "4b0a1101-1f55-4bd6-e248-3c271d5ed92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving logs at logs/fit/1_log_23_12_17_06_10_46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating early stopping callback\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "LuuWDU5dLdWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model with callback\n",
        "CKPT_path_BN = os.path.join(\"Models\",\"Model_ckpt_Digit_mnist_1.h5\")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path_BN, save_best_only=True)"
      ],
      "metadata": {
        "id": "BKviTNzBLkv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the neural network on the chosen dataset without using batch normalization."
      ],
      "metadata": {
        "id": "7YPaqpmoMBRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50 # Number of Epochs\n",
        "VALIDATION_SET = (x_valid,y_valid) # Validation data\n",
        "history = model.fit(x_train,y_train,epochs=EPOCHS,validation_data=VALIDATION_SET,batch_size=64, # Training the model\n",
        " callbacks=[tb_cb,early_stopping_cb,checkpoint_cb],use_multiprocessing=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAHX-JfYME_w",
        "outputId": "6c89e0a6-4141-47ec-f3a8-1428c0fc56e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 2.0316 - accuracy: 0.3639 - val_loss: 1.7391 - val_accuracy: 0.6286\n",
            "Epoch 2/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 1.4735 - accuracy: 0.7148 - val_loss: 1.2097 - val_accuracy: 0.7772\n",
            "Epoch 3/50\n",
            "860/860 [==============================] - 3s 3ms/step - loss: 1.0378 - accuracy: 0.8023 - val_loss: 0.8660 - val_accuracy: 0.8354\n",
            "Epoch 4/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.7825 - accuracy: 0.8385 - val_loss: 0.6791 - val_accuracy: 0.8568\n",
            "Epoch 5/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.6416 - accuracy: 0.8559 - val_loss: 0.5720 - val_accuracy: 0.8700\n",
            "Epoch 6/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.5578 - accuracy: 0.8669 - val_loss: 0.5051 - val_accuracy: 0.8774\n",
            "Epoch 7/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.5033 - accuracy: 0.8750 - val_loss: 0.4601 - val_accuracy: 0.8840\n",
            "Epoch 8/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.4653 - accuracy: 0.8804 - val_loss: 0.4279 - val_accuracy: 0.8872\n",
            "Epoch 9/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.4372 - accuracy: 0.8848 - val_loss: 0.4035 - val_accuracy: 0.8922\n",
            "Epoch 10/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.4156 - accuracy: 0.8883 - val_loss: 0.3847 - val_accuracy: 0.8984\n",
            "Epoch 11/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8921 - val_loss: 0.3696 - val_accuracy: 0.9024\n",
            "Epoch 12/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3838 - accuracy: 0.8945 - val_loss: 0.3562 - val_accuracy: 0.9066\n",
            "Epoch 13/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.3716 - accuracy: 0.8973 - val_loss: 0.3452 - val_accuracy: 0.9084\n",
            "Epoch 14/50\n",
            "860/860 [==============================] - 5s 6ms/step - loss: 0.3611 - accuracy: 0.8997 - val_loss: 0.3357 - val_accuracy: 0.9096\n",
            "Epoch 15/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3519 - accuracy: 0.9019 - val_loss: 0.3272 - val_accuracy: 0.9108\n",
            "Epoch 16/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3438 - accuracy: 0.9035 - val_loss: 0.3200 - val_accuracy: 0.9122\n",
            "Epoch 17/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3365 - accuracy: 0.9055 - val_loss: 0.3133 - val_accuracy: 0.9138\n",
            "Epoch 18/50\n",
            "860/860 [==============================] - 5s 6ms/step - loss: 0.3298 - accuracy: 0.9068 - val_loss: 0.3070 - val_accuracy: 0.9156\n",
            "Epoch 19/50\n",
            "860/860 [==============================] - 4s 5ms/step - loss: 0.3236 - accuracy: 0.9082 - val_loss: 0.3015 - val_accuracy: 0.9166\n",
            "Epoch 20/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3180 - accuracy: 0.9095 - val_loss: 0.2960 - val_accuracy: 0.9184\n",
            "Epoch 21/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.3127 - accuracy: 0.9110 - val_loss: 0.2917 - val_accuracy: 0.9188\n",
            "Epoch 22/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3077 - accuracy: 0.9125 - val_loss: 0.2872 - val_accuracy: 0.9204\n",
            "Epoch 23/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.3031 - accuracy: 0.9138 - val_loss: 0.2829 - val_accuracy: 0.9216\n",
            "Epoch 24/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2987 - accuracy: 0.9147 - val_loss: 0.2790 - val_accuracy: 0.9222\n",
            "Epoch 25/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2946 - accuracy: 0.9160 - val_loss: 0.2748 - val_accuracy: 0.9236\n",
            "Epoch 26/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2907 - accuracy: 0.9171 - val_loss: 0.2716 - val_accuracy: 0.9242\n",
            "Epoch 27/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2868 - accuracy: 0.9180 - val_loss: 0.2683 - val_accuracy: 0.9246\n",
            "Epoch 28/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2833 - accuracy: 0.9191 - val_loss: 0.2648 - val_accuracy: 0.9262\n",
            "Epoch 29/50\n",
            "860/860 [==============================] - 4s 5ms/step - loss: 0.2798 - accuracy: 0.9199 - val_loss: 0.2617 - val_accuracy: 0.9272\n",
            "Epoch 30/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2765 - accuracy: 0.9207 - val_loss: 0.2589 - val_accuracy: 0.9276\n",
            "Epoch 31/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2732 - accuracy: 0.9215 - val_loss: 0.2561 - val_accuracy: 0.9308\n",
            "Epoch 32/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2702 - accuracy: 0.9226 - val_loss: 0.2532 - val_accuracy: 0.9302\n",
            "Epoch 33/50\n",
            "860/860 [==============================] - 4s 5ms/step - loss: 0.2671 - accuracy: 0.9237 - val_loss: 0.2504 - val_accuracy: 0.9308\n",
            "Epoch 34/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2643 - accuracy: 0.9247 - val_loss: 0.2480 - val_accuracy: 0.9332\n",
            "Epoch 35/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2615 - accuracy: 0.9255 - val_loss: 0.2454 - val_accuracy: 0.9338\n",
            "Epoch 36/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2587 - accuracy: 0.9262 - val_loss: 0.2428 - val_accuracy: 0.9346\n",
            "Epoch 37/50\n",
            "860/860 [==============================] - 4s 5ms/step - loss: 0.2561 - accuracy: 0.9276 - val_loss: 0.2409 - val_accuracy: 0.9362\n",
            "Epoch 38/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2535 - accuracy: 0.9278 - val_loss: 0.2384 - val_accuracy: 0.9368\n",
            "Epoch 39/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2509 - accuracy: 0.9288 - val_loss: 0.2360 - val_accuracy: 0.9366\n",
            "Epoch 40/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2485 - accuracy: 0.9294 - val_loss: 0.2339 - val_accuracy: 0.9382\n",
            "Epoch 41/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2461 - accuracy: 0.9302 - val_loss: 0.2316 - val_accuracy: 0.9386\n",
            "Epoch 42/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2437 - accuracy: 0.9308 - val_loss: 0.2295 - val_accuracy: 0.9386\n",
            "Epoch 43/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2415 - accuracy: 0.9312 - val_loss: 0.2275 - val_accuracy: 0.9396\n",
            "Epoch 44/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2392 - accuracy: 0.9319 - val_loss: 0.2255 - val_accuracy: 0.9394\n",
            "Epoch 45/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2370 - accuracy: 0.9329 - val_loss: 0.2237 - val_accuracy: 0.9408\n",
            "Epoch 46/50\n",
            "860/860 [==============================] - 3s 3ms/step - loss: 0.2348 - accuracy: 0.9333 - val_loss: 0.2219 - val_accuracy: 0.9414\n",
            "Epoch 47/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2328 - accuracy: 0.9340 - val_loss: 0.2204 - val_accuracy: 0.9416\n",
            "Epoch 48/50\n",
            "860/860 [==============================] - 4s 4ms/step - loss: 0.2307 - accuracy: 0.9345 - val_loss: 0.2188 - val_accuracy: 0.9422\n",
            "Epoch 49/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2287 - accuracy: 0.9353 - val_loss: 0.2165 - val_accuracy: 0.9426\n",
            "Epoch 50/50\n",
            "860/860 [==============================] - 3s 4ms/step - loss: 0.2266 - accuracy: 0.9358 - val_loss: 0.2148 - val_accuracy: 0.9440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history) # All the losses and accuracy in each epoch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dnFVWz3RNPv2",
        "outputId": "fc7fb112-5c86-4d28-c319-a4e5b287ff08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0   2.031647  0.363945  1.739101        0.6286\n",
              "1   1.473486  0.714782  1.209672        0.7772\n",
              "2   1.037807  0.802291  0.866002        0.8354\n",
              "3   0.782501  0.838473  0.679113        0.8568\n",
              "4   0.641572  0.855945  0.572044        0.8700\n",
              "5   0.557790  0.866909  0.505131        0.8774\n",
              "6   0.503303  0.874964  0.460076        0.8840\n",
              "7   0.465349  0.880364  0.427863        0.8872\n",
              "8   0.437190  0.884782  0.403474        0.8922\n",
              "9   0.415596  0.888345  0.384669        0.8984\n",
              "10  0.398088  0.892109  0.369639        0.9024\n",
              "11  0.383845  0.894545  0.356173        0.9066\n",
              "12  0.371638  0.897327  0.345183        0.9084\n",
              "13  0.361141  0.899655  0.335707        0.9096\n",
              "14  0.351921  0.901873  0.327192        0.9108\n",
              "15  0.343779  0.903527  0.319986        0.9122\n",
              "16  0.336500  0.905545  0.313264        0.9138\n",
              "17  0.329769  0.906764  0.306994        0.9156\n",
              "18  0.323631  0.908200  0.301470        0.9166\n",
              "19  0.317982  0.909545  0.296047        0.9184\n",
              "20  0.312682  0.911000  0.291670        0.9188\n",
              "21  0.307734  0.912491  0.287211        0.9204\n",
              "22  0.303065  0.913818  0.282938        0.9216\n",
              "23  0.298725  0.914673  0.279002        0.9222\n",
              "24  0.294610  0.915964  0.274775        0.9236\n",
              "25  0.290688  0.917109  0.271607        0.9242\n",
              "26  0.286848  0.917964  0.268289        0.9246\n",
              "27  0.283297  0.919073  0.264751        0.9262\n",
              "28  0.279816  0.919927  0.261747        0.9272\n",
              "29  0.276478  0.920673  0.258871        0.9276\n",
              "30  0.273232  0.921545  0.256070        0.9308\n",
              "31  0.270193  0.922600  0.253174        0.9302\n",
              "32  0.267124  0.923709  0.250363        0.9308\n",
              "33  0.264253  0.924655  0.247955        0.9332\n",
              "34  0.261470  0.925509  0.245372        0.9338\n",
              "35  0.258736  0.926182  0.242795        0.9346\n",
              "36  0.256066  0.927600  0.240898        0.9362\n",
              "37  0.253523  0.927764  0.238377        0.9368\n",
              "38  0.250897  0.928764  0.236044        0.9366\n",
              "39  0.248538  0.929382  0.233921        0.9382\n",
              "40  0.246088  0.930200  0.231599        0.9386\n",
              "41  0.243695  0.930764  0.229467        0.9386\n",
              "42  0.241509  0.931182  0.227521        0.9396\n",
              "43  0.239161  0.931855  0.225504        0.9394\n",
              "44  0.237033  0.932855  0.223664        0.9408\n",
              "45  0.234846  0.933291  0.221943        0.9414\n",
              "46  0.232781  0.934018  0.220367        0.9416\n",
              "47  0.230657  0.934545  0.218768        0.9422\n",
              "48  0.228671  0.935327  0.216479        0.9426\n",
              "49  0.226637  0.935836  0.214766        0.9440"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55424743-4adb-48b7-a464-2a2bdb38d276\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.031647</td>\n",
              "      <td>0.363945</td>\n",
              "      <td>1.739101</td>\n",
              "      <td>0.6286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.473486</td>\n",
              "      <td>0.714782</td>\n",
              "      <td>1.209672</td>\n",
              "      <td>0.7772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.037807</td>\n",
              "      <td>0.802291</td>\n",
              "      <td>0.866002</td>\n",
              "      <td>0.8354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.782501</td>\n",
              "      <td>0.838473</td>\n",
              "      <td>0.679113</td>\n",
              "      <td>0.8568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.641572</td>\n",
              "      <td>0.855945</td>\n",
              "      <td>0.572044</td>\n",
              "      <td>0.8700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.557790</td>\n",
              "      <td>0.866909</td>\n",
              "      <td>0.505131</td>\n",
              "      <td>0.8774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.503303</td>\n",
              "      <td>0.874964</td>\n",
              "      <td>0.460076</td>\n",
              "      <td>0.8840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.465349</td>\n",
              "      <td>0.880364</td>\n",
              "      <td>0.427863</td>\n",
              "      <td>0.8872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.437190</td>\n",
              "      <td>0.884782</td>\n",
              "      <td>0.403474</td>\n",
              "      <td>0.8922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.415596</td>\n",
              "      <td>0.888345</td>\n",
              "      <td>0.384669</td>\n",
              "      <td>0.8984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.398088</td>\n",
              "      <td>0.892109</td>\n",
              "      <td>0.369639</td>\n",
              "      <td>0.9024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.383845</td>\n",
              "      <td>0.894545</td>\n",
              "      <td>0.356173</td>\n",
              "      <td>0.9066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.371638</td>\n",
              "      <td>0.897327</td>\n",
              "      <td>0.345183</td>\n",
              "      <td>0.9084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.361141</td>\n",
              "      <td>0.899655</td>\n",
              "      <td>0.335707</td>\n",
              "      <td>0.9096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.351921</td>\n",
              "      <td>0.901873</td>\n",
              "      <td>0.327192</td>\n",
              "      <td>0.9108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.343779</td>\n",
              "      <td>0.903527</td>\n",
              "      <td>0.319986</td>\n",
              "      <td>0.9122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.336500</td>\n",
              "      <td>0.905545</td>\n",
              "      <td>0.313264</td>\n",
              "      <td>0.9138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.329769</td>\n",
              "      <td>0.906764</td>\n",
              "      <td>0.306994</td>\n",
              "      <td>0.9156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.323631</td>\n",
              "      <td>0.908200</td>\n",
              "      <td>0.301470</td>\n",
              "      <td>0.9166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.317982</td>\n",
              "      <td>0.909545</td>\n",
              "      <td>0.296047</td>\n",
              "      <td>0.9184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.312682</td>\n",
              "      <td>0.911000</td>\n",
              "      <td>0.291670</td>\n",
              "      <td>0.9188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.307734</td>\n",
              "      <td>0.912491</td>\n",
              "      <td>0.287211</td>\n",
              "      <td>0.9204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.303065</td>\n",
              "      <td>0.913818</td>\n",
              "      <td>0.282938</td>\n",
              "      <td>0.9216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.298725</td>\n",
              "      <td>0.914673</td>\n",
              "      <td>0.279002</td>\n",
              "      <td>0.9222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.294610</td>\n",
              "      <td>0.915964</td>\n",
              "      <td>0.274775</td>\n",
              "      <td>0.9236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.290688</td>\n",
              "      <td>0.917109</td>\n",
              "      <td>0.271607</td>\n",
              "      <td>0.9242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.286848</td>\n",
              "      <td>0.917964</td>\n",
              "      <td>0.268289</td>\n",
              "      <td>0.9246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.283297</td>\n",
              "      <td>0.919073</td>\n",
              "      <td>0.264751</td>\n",
              "      <td>0.9262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.279816</td>\n",
              "      <td>0.919927</td>\n",
              "      <td>0.261747</td>\n",
              "      <td>0.9272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.276478</td>\n",
              "      <td>0.920673</td>\n",
              "      <td>0.258871</td>\n",
              "      <td>0.9276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.273232</td>\n",
              "      <td>0.921545</td>\n",
              "      <td>0.256070</td>\n",
              "      <td>0.9308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.270193</td>\n",
              "      <td>0.922600</td>\n",
              "      <td>0.253174</td>\n",
              "      <td>0.9302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.267124</td>\n",
              "      <td>0.923709</td>\n",
              "      <td>0.250363</td>\n",
              "      <td>0.9308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.264253</td>\n",
              "      <td>0.924655</td>\n",
              "      <td>0.247955</td>\n",
              "      <td>0.9332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.261470</td>\n",
              "      <td>0.925509</td>\n",
              "      <td>0.245372</td>\n",
              "      <td>0.9338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.258736</td>\n",
              "      <td>0.926182</td>\n",
              "      <td>0.242795</td>\n",
              "      <td>0.9346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.927600</td>\n",
              "      <td>0.240898</td>\n",
              "      <td>0.9362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.253523</td>\n",
              "      <td>0.927764</td>\n",
              "      <td>0.238377</td>\n",
              "      <td>0.9368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.250897</td>\n",
              "      <td>0.928764</td>\n",
              "      <td>0.236044</td>\n",
              "      <td>0.9366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.248538</td>\n",
              "      <td>0.929382</td>\n",
              "      <td>0.233921</td>\n",
              "      <td>0.9382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.246088</td>\n",
              "      <td>0.930200</td>\n",
              "      <td>0.231599</td>\n",
              "      <td>0.9386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.243695</td>\n",
              "      <td>0.930764</td>\n",
              "      <td>0.229467</td>\n",
              "      <td>0.9386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.241509</td>\n",
              "      <td>0.931182</td>\n",
              "      <td>0.227521</td>\n",
              "      <td>0.9396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.239161</td>\n",
              "      <td>0.931855</td>\n",
              "      <td>0.225504</td>\n",
              "      <td>0.9394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.237033</td>\n",
              "      <td>0.932855</td>\n",
              "      <td>0.223664</td>\n",
              "      <td>0.9408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.234846</td>\n",
              "      <td>0.933291</td>\n",
              "      <td>0.221943</td>\n",
              "      <td>0.9414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.232781</td>\n",
              "      <td>0.934018</td>\n",
              "      <td>0.220367</td>\n",
              "      <td>0.9416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.230657</td>\n",
              "      <td>0.934545</td>\n",
              "      <td>0.218768</td>\n",
              "      <td>0.9422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.228671</td>\n",
              "      <td>0.935327</td>\n",
              "      <td>0.216479</td>\n",
              "      <td>0.9426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.226637</td>\n",
              "      <td>0.935836</td>\n",
              "      <td>0.214766</td>\n",
              "      <td>0.9440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55424743-4adb-48b7-a464-2a2bdb38d276')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55424743-4adb-48b7-a464-2a2bdb38d276 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55424743-4adb-48b7-a464-2a2bdb38d276');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c443c543-c396-4e4b-b052-729145798e8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c443c543-c396-4e4b-b052-729145798e8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c443c543-c396-4e4b-b052-729145798e8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot() # Plotting all of the accuracy and losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Rmm-Qc6FNcyH",
        "outputId": "d5f8e62f-d276-432b-8905-85461866dae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_model = tf.keras.models.load_model(CKPT_path_BN) # Loading model\n",
        "ckpt_model.evaluate(x_test,y_test) # Evaluating the performance of the model on test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ0AMG90NwVc",
        "outputId": "d2879b58-fc10-4fe0-9a00-61cfb8c6aefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22334037721157074, 0.9380000233650208]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Accuracy of ANN Model is **93.72** %"
      ],
      "metadata": {
        "id": "2xHlSBpFNzN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the probability of 5 samples randomly\n",
        "print(\"Probability of each number for image of testing data:- \\n\")\n",
        "for j in range(5):\n",
        "  idx = np.random.randint(0,10000,1)[0]\n",
        "  y_prob_lst = ckpt_model.predict(x_test[idx-1:idx]).round(3)[0]\n",
        "  print(\"\\nNumber : Probability\")\n",
        "  for i in range(10):\n",
        "    print(i,\" : \",y_prob_lst[i])\n",
        "  y_predict = np.argmax(y_prob_lst,axis=-1)\n",
        "  print(\"Predicted final output is: \",y_predict,\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUq5jQkOE6u",
        "outputId": "61ce4b2d-f4cc-4c64-f69d-6cb9df10d07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of each number for image of testing data:- \n",
            "\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "\n",
            "Number : Probability\n",
            "0  :  0.0\n",
            "1  :  0.001\n",
            "2  :  0.005\n",
            "3  :  0.308\n",
            "4  :  0.291\n",
            "5  :  0.024\n",
            "6  :  0.0\n",
            "7  :  0.061\n",
            "8  :  0.019\n",
            "9  :  0.291\n",
            "Predicted final output is:  3 \n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "Number : Probability\n",
            "0  :  1.0\n",
            "1  :  0.0\n",
            "2  :  0.0\n",
            "3  :  0.0\n",
            "4  :  0.0\n",
            "5  :  0.0\n",
            "6  :  0.0\n",
            "7  :  0.0\n",
            "8  :  0.0\n",
            "9  :  0.0\n",
            "Predicted final output is:  0 \n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "Number : Probability\n",
            "0  :  0.0\n",
            "1  :  0.0\n",
            "2  :  0.0\n",
            "3  :  0.0\n",
            "4  :  0.0\n",
            "5  :  0.0\n",
            "6  :  0.0\n",
            "7  :  0.0\n",
            "8  :  1.0\n",
            "9  :  0.0\n",
            "Predicted final output is:  8 \n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "Number : Probability\n",
            "0  :  0.0\n",
            "1  :  0.214\n",
            "2  :  0.65\n",
            "3  :  0.131\n",
            "4  :  0.0\n",
            "5  :  0.0\n",
            "6  :  0.001\n",
            "7  :  0.0\n",
            "8  :  0.003\n",
            "9  :  0.0\n",
            "Predicted final output is:  2 \n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "Number : Probability\n",
            "0  :  0.973\n",
            "1  :  0.0\n",
            "2  :  0.001\n",
            "3  :  0.001\n",
            "4  :  0.0\n",
            "5  :  0.014\n",
            "6  :  0.011\n",
            "7  :  0.0\n",
            "8  :  0.0\n",
            "9  :  0.0\n",
            "Predicted final output is:  0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement batch normalization layers in the neural network and train the model again."
      ],
      "metadata": {
        "id": "ls4nRk_xTSLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Added kernel regularization,batch normalization,dropout and leakyrelu activation function\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=[28,28]))\n",
        "model.add(Dense(units=256,kernel_regularizer=regularizers.L1L2(0.0001,0.0001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=128,kernel_regularizer=regularizers.L1L2(0.0001,0.0001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=64,kernel_regularizer=regularizers.L1L2(0.0001,0.0001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=32,kernel_regularizer=regularizers.L1L2(0.0001,0.0001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=16,kernel_regularizer=regularizers.L1L2(0.0001,0.0001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units=10,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "iCa2b__xTXde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFd1HR5tTn0_",
        "outputId": "1bba300d-5968-4875-f529-da51510a3355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 16)                64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 16)                0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246874 (964.35 KB)\n",
            "Trainable params: 245882 (960.48 KB)\n",
            "Non-trainable params: 992 (3.88 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_log_path(log_dir=\"logs/fit\"):\n",
        "  filename = time.strftime(\"2_log_%y_%m_%d_%H_%M_%S\")\n",
        "  logs_path = os.path.join(log_dir, filename)\n",
        "  print(f\"Saving logs at {logs_path}\")\n",
        "  return logs_path\n",
        "log_dirs = get_log_path()\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dirs)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n",
        "CKPT_path = os.path.join(\"Models\",\"Model_ckpt_Digit_mnist_2.h5\")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path, save_best_only=True)\n",
        "EPOCHS = 50\n",
        "VALIDATION_SET = (x_valid, y_valid)\n",
        "loss_function = \"sparse_categorical_crossentropy\"\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\"accuracy\"]\n",
        "model.compile(\n",
        " loss=loss_function,\n",
        " optimizer=OPTIMIZER,\n",
        " metrics=METRICS\n",
        ")\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=VALIDATION_SET, batch_size=64,\n",
        " callbacks=[tb_cb, early_stopping_cb, checkpoint_cb],use_multiprocessing=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvu2hlksT7Hf",
        "outputId": "5dfa218c-323f-4dbe-d2c8-76b8597165d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving logs at logs/fit/2_log_23_12_17_06_13_42\n",
            "Epoch 1/50\n",
            "860/860 [==============================] - 13s 9ms/step - loss: 1.1519 - accuracy: 0.8733 - val_loss: 0.6645 - val_accuracy: 0.9406\n",
            "Epoch 2/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.6747 - accuracy: 0.9228 - val_loss: 0.5047 - val_accuracy: 0.9586\n",
            "Epoch 3/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.5818 - accuracy: 0.9293 - val_loss: 0.4571 - val_accuracy: 0.9602\n",
            "Epoch 4/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.5273 - accuracy: 0.9365 - val_loss: 0.4325 - val_accuracy: 0.9594\n",
            "Epoch 5/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.4990 - accuracy: 0.9395 - val_loss: 0.4089 - val_accuracy: 0.9640\n",
            "Epoch 6/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4797 - accuracy: 0.9405 - val_loss: 0.3839 - val_accuracy: 0.9658\n",
            "Epoch 7/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4607 - accuracy: 0.9435 - val_loss: 0.3992 - val_accuracy: 0.9600\n",
            "Epoch 8/50\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.4518 - accuracy: 0.9437 - val_loss: 0.3552 - val_accuracy: 0.9690\n",
            "Epoch 9/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4339 - accuracy: 0.9463 - val_loss: 0.3599 - val_accuracy: 0.9676\n",
            "Epoch 10/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.4207 - accuracy: 0.9484 - val_loss: 0.3482 - val_accuracy: 0.9680\n",
            "Epoch 11/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.4139 - accuracy: 0.9491 - val_loss: 0.3576 - val_accuracy: 0.9644\n",
            "Epoch 12/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.4053 - accuracy: 0.9492 - val_loss: 0.3391 - val_accuracy: 0.9692\n",
            "Epoch 13/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3896 - accuracy: 0.9514 - val_loss: 0.3313 - val_accuracy: 0.9658\n",
            "Epoch 14/50\n",
            "860/860 [==============================] - 7s 9ms/step - loss: 0.3955 - accuracy: 0.9499 - val_loss: 0.3334 - val_accuracy: 0.9680\n",
            "Epoch 15/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3858 - accuracy: 0.9507 - val_loss: 0.3214 - val_accuracy: 0.9700\n",
            "Epoch 16/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3822 - accuracy: 0.9500 - val_loss: 0.3095 - val_accuracy: 0.9724\n",
            "Epoch 17/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3725 - accuracy: 0.9521 - val_loss: 0.3026 - val_accuracy: 0.9710\n",
            "Epoch 18/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3775 - accuracy: 0.9514 - val_loss: 0.3073 - val_accuracy: 0.9692\n",
            "Epoch 19/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3669 - accuracy: 0.9528 - val_loss: 0.3020 - val_accuracy: 0.9696\n",
            "Epoch 20/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3682 - accuracy: 0.9520 - val_loss: 0.3172 - val_accuracy: 0.9704\n",
            "Epoch 21/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3590 - accuracy: 0.9534 - val_loss: 0.2936 - val_accuracy: 0.9740\n",
            "Epoch 22/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3580 - accuracy: 0.9534 - val_loss: 0.2963 - val_accuracy: 0.9710\n",
            "Epoch 23/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3573 - accuracy: 0.9529 - val_loss: 0.2834 - val_accuracy: 0.9728\n",
            "Epoch 24/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3548 - accuracy: 0.9535 - val_loss: 0.2980 - val_accuracy: 0.9694\n",
            "Epoch 25/50\n",
            "860/860 [==============================] - 9s 10ms/step - loss: 0.3539 - accuracy: 0.9529 - val_loss: 0.3125 - val_accuracy: 0.9678\n",
            "Epoch 26/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3511 - accuracy: 0.9544 - val_loss: 0.2895 - val_accuracy: 0.9734\n",
            "Epoch 27/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3496 - accuracy: 0.9545 - val_loss: 0.2961 - val_accuracy: 0.9730\n",
            "Epoch 28/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3497 - accuracy: 0.9543 - val_loss: 0.3205 - val_accuracy: 0.9674\n",
            "Epoch 29/50\n",
            "860/860 [==============================] - 8s 10ms/step - loss: 0.3510 - accuracy: 0.9529 - val_loss: 0.2975 - val_accuracy: 0.9700\n",
            "Epoch 30/50\n",
            "860/860 [==============================] - 8s 9ms/step - loss: 0.3415 - accuracy: 0.9562 - val_loss: 0.2863 - val_accuracy: 0.9722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_model = tf.keras.models.load_model(CKPT_path)\n",
        "ckpt_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGQ6jG8wT8vA",
        "outputId": "d4422975-6229-4b5c-ec8c-4f2e03789879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28808528184890747, 0.9732000231742859]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the training and validation performance (e.g., accuracy, loss) between the models with and\n",
        "without batch normalization."
      ],
      "metadata": {
        "id": "NGCPAXfdXhlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pd.DataFrame(history.history).plot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9DZjDM95XJQz",
        "outputId": "e37d3d16-ef05-446b-b468-7746a48f2304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Performance Before Normalisation\n",
        "ckpt_model = tf.keras.models.load_model(CKPT_path_BN) # Loading model\n",
        "ckpt_model.evaluate(x_test,y_test) # Evaluating the performance of the model on test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RlPcOuIYcMr",
        "outputId": "40052ab7-326e-42b1-ac21-865ee42cee77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2233 - accuracy: 0.9380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22334037721157074, 0.9380000233650208]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, Accuracy before Normalisation is 93.8 %"
      ],
      "metadata": {
        "id": "00Zqj1AVcGvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Performance after Normalisation\n",
        "ckpt_model = tf.keras.models.load_model(CKPT_path)\n",
        "ckpt_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRSVPGurY1M3",
        "outputId": "5ce363c5-f18c-4087-9342-201780d18143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28808528184890747, 0.9732000231742859]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, Accuracy after Batch Normalisation is 97.3 %"
      ],
      "metadata": {
        "id": "n6iyunOkcYUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss the impact of batch normalization on the training process and the performance of the neural\n",
        "network."
      ],
      "metadata": {
        "id": "EanX5AzadI0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization (BN) is a technique in deep learning that has had a significant impact on the training process and performance of neural networks. Introduced by Sergey Ioffe and Christian Szegedy in 2015, BN has become a standard component in many modern neural network architectures. Here are some key aspects of the impact of batch normalization:\n",
        "\n",
        "1. **Accelerated Training Convergence:**\n",
        "   - BN helps in reducing internal covariate shift, which is the change in the distribution of the inputs to a neural network's layers during training. By normalizing the inputs in each mini-batch, BN stabilizes and speeds up the training process. Networks with BN tend to converge faster compared to those without it.\n",
        "\n",
        "2. **Increased Learning Rates:**\n",
        "   - Batch Normalization allows for the use of higher learning rates during training. This is because it mitigates the risk of exploding or vanishing gradients, which can occur when learning rates are too high or too low. Higher learning rates can lead to faster convergence and improved generalization.\n",
        "\n",
        "3. **Reduced Sensitivity to Weight Initialization:**\n",
        "   - Neural networks are sensitive to the choice of initial weights. Batch Normalization reduces this sensitivity by normalizing the inputs, making the network less dependent on the choice of initial weights. This allows for more flexibility in choosing initialization schemes.\n",
        "\n",
        "4. **Regularization Effect:**\n",
        "   - Batch Normalization has a slight regularization effect, reducing the need for other regularization techniques like dropout. This is because BN introduces noise during training due to the mini-batch statistics, which can act as a form of regularization and improve the generalization of the model.\n",
        "\n",
        "5. **Mitigation of Vanishing/Exploding Gradients:**\n",
        "   - By normalizing the inputs, BN helps mitigate the vanishing and exploding gradient problems. This is particularly important in deep networks where gradients can diminish or explode as they propagate through many layers. BN ensures that the activations stay within a reasonable range.\n",
        "\n",
        "6. **Applicability to Various Architectures:**\n",
        "   - Batch Normalization is applicable to various types of neural network architectures, including feedforward networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Its versatility has contributed to its widespread adoption across different domains.\n",
        "\n",
        "7. **Improved Robustness to Hyperparameter Choices:**\n",
        "   - BN makes neural networks less sensitive to hyperparameter choices, such as learning rate and weight initialization. This makes it easier for practitioners to experiment with different hyperparameters without risking the stability of the training process.\n",
        "\n",
        "Despite its many advantages, it's worth noting that batch normalization has some drawbacks, such as its dependence on mini-batch statistics during training and potential issues in certain scenarios like small batch sizes. These challenges have led to the development of variations such as Layer Normalization and Group Normalization, which aim to address some of the limitations of batch normalization in specific situations."
      ],
      "metadata": {
        "id": "QRahzAtLdz2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Experimentation and analysis."
      ],
      "metadata": {
        "id": "8YLj-Tond9x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with different batch sizes and observe the effect on the training dynamics and model\n",
        "performance."
      ],
      "metadata": {
        "id": "gydTX49LfDEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For Batch Size = 50\n",
        "def get_log_path(log_dir=\"logs/fit\"):\n",
        "  filename = time.strftime(\"3_log_%y_%m_%d_%H_%M_%S\")\n",
        "  logs_path = os.path.join(log_dir, filename)\n",
        "  print(f\"Saving logs at {logs_path}\")\n",
        "  return logs_path\n",
        "log_dirs = get_log_path()\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dirs)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n",
        "CKPT_path = os.path.join(\"Models\",\"Model_ckpt_Digit_mnist_2.h5\")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path, save_best_only=True)\n",
        "EPOCHS = 50\n",
        "VALIDATION_SET = (x_valid, y_valid)\n",
        "loss_function = \"sparse_categorical_crossentropy\"\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\"accuracy\"]\n",
        "model.compile(\n",
        " loss=loss_function,\n",
        " optimizer=OPTIMIZER,\n",
        " metrics=METRICS\n",
        ")\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=VALIDATION_SET, batch_size=50,\n",
        " callbacks=[tb_cb, early_stopping_cb, checkpoint_cb],use_multiprocessing=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JanzuYqxfGFQ",
        "outputId": "f9b7e22c-98c7-4d25-a9b6-628d02e08491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving logs at logs/fit/3_log_23_12_17_06_38_19\n",
            "Epoch 1/50\n",
            "1100/1100 [==============================] - 14s 8ms/step - loss: 0.3804 - accuracy: 0.9482 - val_loss: 0.2976 - val_accuracy: 0.9734\n",
            "Epoch 2/50\n",
            "1100/1100 [==============================] - 9s 8ms/step - loss: 0.3760 - accuracy: 0.9497 - val_loss: 0.2984 - val_accuracy: 0.9730\n",
            "Epoch 3/50\n",
            "1100/1100 [==============================] - 8s 8ms/step - loss: 0.3756 - accuracy: 0.9495 - val_loss: 0.3080 - val_accuracy: 0.9692\n",
            "Epoch 4/50\n",
            "1100/1100 [==============================] - 8s 7ms/step - loss: 0.3728 - accuracy: 0.9495 - val_loss: 0.2869 - val_accuracy: 0.9766\n",
            "Epoch 5/50\n",
            "1100/1100 [==============================] - 9s 8ms/step - loss: 0.3697 - accuracy: 0.9496 - val_loss: 0.3131 - val_accuracy: 0.9690\n",
            "Epoch 6/50\n",
            "1100/1100 [==============================] - 8s 7ms/step - loss: 0.3717 - accuracy: 0.9494 - val_loss: 0.3133 - val_accuracy: 0.9662\n",
            "Epoch 7/50\n",
            "1100/1100 [==============================] - 9s 8ms/step - loss: 0.3732 - accuracy: 0.9497 - val_loss: 0.3123 - val_accuracy: 0.9686\n",
            "Epoch 8/50\n",
            "1100/1100 [==============================] - 10s 9ms/step - loss: 0.3667 - accuracy: 0.9507 - val_loss: 0.2910 - val_accuracy: 0.9728\n",
            "Epoch 9/50\n",
            "1100/1100 [==============================] - 8s 7ms/step - loss: 0.3640 - accuracy: 0.9515 - val_loss: 0.2996 - val_accuracy: 0.9690\n",
            "Epoch 10/50\n",
            "1100/1100 [==============================] - 8s 8ms/step - loss: 0.3669 - accuracy: 0.9499 - val_loss: 0.2902 - val_accuracy: 0.9716\n",
            "Epoch 11/50\n",
            "1100/1100 [==============================] - 9s 8ms/step - loss: 0.3620 - accuracy: 0.9518 - val_loss: 0.2895 - val_accuracy: 0.9734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Performance after Normalisation\n",
        "ckpt_model = tf.keras.models.load_model(CKPT_path)\n",
        "ckpt_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n10LamiWg8ad",
        "outputId": "d4c64022-f246-401d-861d-772895de3a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29024964570999146, 0.9745000004768372]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, from above accuracy is 97.45 for Batch Size 50"
      ],
      "metadata": {
        "id": "8T9EtltOhGg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For Batch Size = 100\n",
        "def get_log_path(log_dir=\"logs/fit\"):\n",
        "  filename = time.strftime(\"3_log_%y_%m_%d_%H_%M_%S\")\n",
        "  logs_path = os.path.join(log_dir, filename)\n",
        "  print(f\"Saving logs at {logs_path}\")\n",
        "  return logs_path\n",
        "log_dirs = get_log_path()\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dirs)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n",
        "CKPT_path = os.path.join(\"Models\",\"Model_ckpt_Digit_mnist_2.h5\")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path, save_best_only=True)\n",
        "EPOCHS = 50\n",
        "VALIDATION_SET = (x_valid, y_valid)\n",
        "loss_function = \"sparse_categorical_crossentropy\"\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\"accuracy\"]\n",
        "model.compile(\n",
        " loss=loss_function,\n",
        " optimizer=OPTIMIZER,\n",
        " metrics=METRICS\n",
        ")\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=VALIDATION_SET, batch_size=100,\n",
        " callbacks=[tb_cb, early_stopping_cb, checkpoint_cb],use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3bCHOmKhSYI",
        "outputId": "f66e5e10-0971-4e72-e472-9318df6a704f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving logs at logs/fit/3_log_23_12_17_06_45_32\n",
            "Epoch 1/50\n",
            "550/550 [==============================] - 8s 8ms/step - loss: 0.3167 - accuracy: 0.9626 - val_loss: 0.2690 - val_accuracy: 0.9750\n",
            "Epoch 2/50\n",
            "550/550 [==============================] - 5s 8ms/step - loss: 0.3119 - accuracy: 0.9613 - val_loss: 0.2596 - val_accuracy: 0.9764\n",
            "Epoch 3/50\n",
            "550/550 [==============================] - 6s 10ms/step - loss: 0.3119 - accuracy: 0.9594 - val_loss: 0.2613 - val_accuracy: 0.9760\n",
            "Epoch 4/50\n",
            "550/550 [==============================] - 4s 7ms/step - loss: 0.3040 - accuracy: 0.9624 - val_loss: 0.2580 - val_accuracy: 0.9740\n",
            "Epoch 5/50\n",
            "550/550 [==============================] - 5s 8ms/step - loss: 0.3050 - accuracy: 0.9613 - val_loss: 0.2624 - val_accuracy: 0.9732\n",
            "Epoch 6/50\n",
            "550/550 [==============================] - 4s 7ms/step - loss: 0.3045 - accuracy: 0.9604 - val_loss: 0.2818 - val_accuracy: 0.9674\n",
            "Epoch 7/50\n",
            "550/550 [==============================] - 4s 7ms/step - loss: 0.3019 - accuracy: 0.9605 - val_loss: 0.2738 - val_accuracy: 0.9708\n",
            "Epoch 8/50\n",
            "550/550 [==============================] - 5s 8ms/step - loss: 0.2983 - accuracy: 0.9615 - val_loss: 0.2706 - val_accuracy: 0.9694\n",
            "Epoch 9/50\n",
            "550/550 [==============================] - 4s 8ms/step - loss: 0.3004 - accuracy: 0.9610 - val_loss: 0.2691 - val_accuracy: 0.9724\n",
            "Epoch 10/50\n",
            "550/550 [==============================] - 4s 7ms/step - loss: 0.2948 - accuracy: 0.9618 - val_loss: 0.2653 - val_accuracy: 0.9716\n",
            "Epoch 11/50\n",
            "550/550 [==============================] - 5s 8ms/step - loss: 0.2973 - accuracy: 0.9612 - val_loss: 0.2651 - val_accuracy: 0.9718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Performance after Normalisation\n",
        "ckpt_model = tf.keras.models.load_model(CKPT_path)\n",
        "ckpt_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPMVQlcpiAiU",
        "outputId": "48c8dc51-1bef-4f56-b15d-2e5f4000f1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.9744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25992047786712646, 0.974399983882904]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, For Batch Size 100 Accuracy is 97.44 %"
      ],
      "metadata": {
        "id": "AQgkjPJ3iovr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For Batch Size = 500\n",
        "def get_log_path(log_dir=\"logs/fit\"):\n",
        "  filename = time.strftime(\"3_log_%y_%m_%d_%H_%M_%S\")\n",
        "  logs_path = os.path.join(log_dir, filename)\n",
        "  print(f\"Saving logs at {logs_path}\")\n",
        "  return logs_path\n",
        "log_dirs = get_log_path()\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dirs)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)\n",
        "CKPT_path = os.path.join(\"Models\",\"Model_ckpt_Digit_mnist_2.h5\")\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path, save_best_only=True)\n",
        "EPOCHS = 50\n",
        "VALIDATION_SET = (x_valid, y_valid)\n",
        "loss_function = \"sparse_categorical_crossentropy\"\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\"accuracy\"]\n",
        "model.compile(\n",
        " loss=loss_function,\n",
        " optimizer=OPTIMIZER,\n",
        " metrics=METRICS\n",
        ")\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=VALIDATION_SET, batch_size=500,\n",
        " callbacks=[tb_cb, early_stopping_cb, checkpoint_cb],use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLQYx4q0ipPJ",
        "outputId": "7ffcc837-c0b1-4bd7-a299-c30cf89a232b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving logs at logs/fit/3_log_23_12_17_06_51_01\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 5s 12ms/step - loss: 0.2462 - accuracy: 0.9739 - val_loss: 0.2146 - val_accuracy: 0.9800\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.2221 - accuracy: 0.9761 - val_loss: 0.2060 - val_accuracy: 0.9802\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2227 - accuracy: 0.9749 - val_loss: 0.2090 - val_accuracy: 0.9802\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2207 - accuracy: 0.9750 - val_loss: 0.2109 - val_accuracy: 0.9768\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2165 - accuracy: 0.9751 - val_loss: 0.2087 - val_accuracy: 0.9764\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.2129 - accuracy: 0.9756 - val_loss: 0.1962 - val_accuracy: 0.9806\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.2148 - accuracy: 0.9748 - val_loss: 0.2005 - val_accuracy: 0.9796\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2125 - accuracy: 0.9746 - val_loss: 0.1987 - val_accuracy: 0.9790\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2072 - accuracy: 0.9753 - val_loss: 0.2034 - val_accuracy: 0.9752\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.2124 - accuracy: 0.9743 - val_loss: 0.1936 - val_accuracy: 0.9798\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.2057 - accuracy: 0.9751 - val_loss: 0.1914 - val_accuracy: 0.9804\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2040 - accuracy: 0.9756 - val_loss: 0.2117 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2085 - accuracy: 0.9740 - val_loss: 0.1998 - val_accuracy: 0.9778\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2041 - accuracy: 0.9758 - val_loss: 0.2004 - val_accuracy: 0.9774\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.2057 - accuracy: 0.9749 - val_loss: 0.1910 - val_accuracy: 0.9786\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 2s 16ms/step - loss: 0.2005 - accuracy: 0.9759 - val_loss: 0.1930 - val_accuracy: 0.9784\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2051 - accuracy: 0.9739 - val_loss: 0.1935 - val_accuracy: 0.9784\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.9760 - val_loss: 0.1965 - val_accuracy: 0.9774\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.1984 - accuracy: 0.9753 - val_loss: 0.1953 - val_accuracy: 0.9794\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.1993 - accuracy: 0.9756 - val_loss: 0.1904 - val_accuracy: 0.9798\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9749 - val_loss: 0.1951 - val_accuracy: 0.9782\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9752 - val_loss: 0.1973 - val_accuracy: 0.9758\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1984 - accuracy: 0.9759 - val_loss: 0.1936 - val_accuracy: 0.9778\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1953 - accuracy: 0.9759 - val_loss: 0.1996 - val_accuracy: 0.9780\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 2s 21ms/step - loss: 0.1977 - accuracy: 0.9758 - val_loss: 0.1958 - val_accuracy: 0.9772\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.1988 - accuracy: 0.9755 - val_loss: 0.2033 - val_accuracy: 0.9744\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.1984 - accuracy: 0.9755 - val_loss: 0.2075 - val_accuracy: 0.9738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Performance after Normalisation\n",
        "ckpt_model = tf.keras.models.load_model(CKPT_path)\n",
        "ckpt_model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uekyEnfGjEJM",
        "outputId": "96117361-0221-4140-a864-7ec5cfcfc7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1938 - accuracy: 0.9757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19379045069217682, 0.9757000207901001]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, The accuracy for Batch 500 is 97.57 %"
      ],
      "metadata": {
        "id": "1YFTwRzmkUE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss the advantages and potential limitations of batch normalization in improving the training of\n",
        "neural networks."
      ],
      "metadata": {
        "id": "8lxWJLKrlQak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages of Batch Normalization:\n",
        "\n",
        "1. **Stabilizes and Accelerates Training:**\n",
        "   - Batch Normalization significantly reduces the internal covariate shift by normalizing the inputs in each mini-batch. This stabilization leads to faster convergence during training, as the optimization process is less hindered by changing input distributions.\n",
        "\n",
        "2. **Allows for Higher Learning Rates:**\n",
        "   - BN mitigates the risk of exploding or vanishing gradients, allowing for the use of higher learning rates. This, in turn, accelerates the training process and can lead to better convergence.\n",
        "\n",
        "3. **Reduces Sensitivity to Weight Initialization:**\n",
        "   - Neural networks are often sensitive to the choice of initial weights. Batch Normalization helps alleviate this sensitivity, making it easier to train deep networks with a wider range of weight initializations.\n",
        "\n",
        "4. **Acts as a Regularization Technique:**\n",
        "   - Batch Normalization introduces a slight noise during training due to the mini-batch statistics. This acts as a form of regularization, reducing the need for other regularization techniques like dropout and contributing to better generalization.\n",
        "\n",
        "5. **Adaptable to Different Network Architectures:**\n",
        "   - Batch Normalization is applicable to various neural network architectures, including feedforward networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Its versatility has contributed to its widespread adoption.\n",
        "\n",
        "6. **Reduces Dependency on Hyperparameter Choices:**\n",
        "   - BN makes neural networks less sensitive to certain hyperparameter choices, such as learning rate and weight initialization. This flexibility allows practitioners to experiment with hyperparameters more freely.\n",
        "\n",
        "### Limitations and Challenges of Batch Normalization:\n",
        "\n",
        "1. **Dependency on Mini-Batch Statistics:**\n",
        "   - Batch Normalization relies on statistics computed from the mini-batch during training. In situations with very small batch sizes, these statistics may not accurately represent the entire dataset, leading to suboptimal performance.\n",
        "\n",
        "2. **Incompatibility with Online Learning:**\n",
        "   - BN is designed for batch learning and might not be suitable for online learning scenarios where data arrives sequentially. This is because it requires statistics calculated over the entire mini-batch.\n",
        "\n",
        "3. **Effectiveness May Diminish with Small Batch Sizes:**\n",
        "   - In practice, Batch Normalization's effectiveness can diminish with very small batch sizes. It may not provide as much benefit in scenarios where the mini-batch statistics have high variance.\n",
        "\n",
        "4. **Not Always Beneficial in Recurrent Networks:**\n",
        "   - While Batch Normalization is effective in many types of networks, its application in recurrent neural networks (RNNs) can be more challenging. It may disrupt the learning dynamics of recurrent connections and is often replaced by alternatives like Layer Normalization in RNNs.\n",
        "\n",
        "5. **Additional Computational Overhead:**\n",
        "   - Batch Normalization introduces extra computations during both training and inference, which can impact the overall efficiency of the network. This might be a consideration in resource-constrained environments.\n",
        "\n",
        "6. **Normalization During Inference:**\n",
        "   - During inference, the normalization parameters need to be applied to individual examples, which may require maintaining running averages. This introduces a slight discrepancy between training and inference, and in certain cases, this mismatch might affect performance.\n",
        "\n",
        "7. **Sensitivity to Learning Rate:**\n",
        "   - Batch Normalization can be sensitive to the choice of learning rate. Extremely high learning rates may lead to unstable training dynamics, and finding the right learning rate can require some experimentation.\n",
        "\n",
        "Despite these limitations, Batch Normalization remains a powerful and widely used technique in deep learning. Researchers have proposed variations, such as Layer Normalization and Group Normalization, to address some of these challenges in specific contexts. Additionally, ongoing research aims to improve the understanding of the factors influencing the effectiveness of normalization techniques in different scenarios."
      ],
      "metadata": {
        "id": "n1EpgwoElcBI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxKTOS7-lc0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN20U7zftjWzFLPs5kQNNZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}